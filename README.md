# Resume Parser & Job Classifier

## ğŸŒ Visit the App Online

ğŸ”— [Click here to try the Resume Parser](https://resume-parser-matcher.onrender.com)

This project is a web application that parses resumes (PDF/DOCX), extracts relevant information, and classifies the candidate into a suitable job category using Natural Language Processing (NLP) and Machine Learning (ML).

---

## ğŸ” Features

-  Upload resumes in `.pdf` or `.docx` formats
-  Extract name, email, phone number, skills, education, experience
- ï¿½ Detect coding profile links (GitHub, LeetCode, etc.)
-  Clean and preprocess resume content using NLP (NLTK & spaCy)
-  Transform resume text using TF-IDF vectorization
-  Predict job category using a trained Logistic Regression model
-  ATS (Applicant Tracking System) score calculator
-  Uses pre-trained model and vectorizer stored as `.pkl` files

---

## Tech Stack

- **Frontend:** Streamlit
- **Backend:** Python
- **ML/NLP Libraries:** Scikit-learn, NLTK, spaCy, Joblib, TfidfVectorizer
- **File Handling:** PyMuPDF (fitz), python-docx, textract

---

## ğŸ“ File Structure

â”œâ”€â”€ app.py                      # Main Streamlit app
â”œâ”€â”€ utils.py                   # Text extraction and cleaning utilities
â”œâ”€â”€ parser_functions.py        # Functions for extracting structured data
â”œâ”€â”€ tfidf_vectorizer.pkl       # Trained TF-IDF vectorizer
â”œâ”€â”€ logistic_regression_model.pkl  # Trained Logistic Regression model
â”œâ”€â”€ Dataset_Resume.csv         # Resume dataset used for training
â”œâ”€â”€ dataset.ipynb              # Notebook for data cleaning and model training
â”œâ”€â”€ requirements.txt           # All dependencies
â””â”€â”€ README.md                  # This file



